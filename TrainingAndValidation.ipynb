{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 3: Training und Visualisierung\n",
    "\n",
    "Hier werden Sie ein neuronales Netzwerk auf den Bilddaten trainieren und testen. Stellen Sie Fragen und versuchen Sie, ein tieferes Verständnis von Faltungsnetzen und Pytorch zu entwickeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dieser Code kopiert und importiert notwendige Dateien in die virtuelle Maschine von Colab.\n",
    "\"\"\"\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/Criscraft/HackathonDigitaltag2022.git'\n",
    "    os.chdir('HackathonDigitaltag2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from models import Network\n",
    "import utils\n",
    "\n",
    "# Konstanten\n",
    "DATA_TRAIN = 'data/train/'\n",
    "DATA_TEST = 'data/val/'\n",
    "MAX_EPOCH = 100\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_LOG_PATH = 'train_log.dat'\n",
    "TEST_LOG_PATH = 'test_log.dat'\n",
    "#TODO: Ändern Sie NO_CUDA auf False, falls Sie Ihre GPU benutzen wollen\n",
    "NO_CUDA = False\n",
    "MODEL_FILE_NAME = 'saved_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung des Netzwerks\n",
    "\n",
    "Erstellen Sie ein Netzwerk und transferieren Sie es auf die CPU oder die GPU. Die Fehlerfunktion ```nn.CrossEntropyLoss()``` und der Optimierer (etwa ```torch.optim.SGD```) werden hier gewählt. Setzen Sie die Lernrate zunächst auf 0.01 und den Impuls (momentum) auf 0.9. Die Parameter des Modells ```model.parameters()``` werden dem Optimierer zur Verfügung gestellt. Der Optimierer wird nur diese Parameter modifizieren, um die Fehlerfunktion zu minimieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not NO_CUDA and torch.cuda.is_available()\n",
    "cuda_args = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "#Das Pytorch Device regelt, ob 'cpu' oder 'cuda' (also die GPU) genutzt wird\n",
    "device = torch.device(\"cuda\") if use_cuda else torch.device(\"cpu\")\n",
    "\n",
    "#Netzwerk erstellen und auf das Device transferieren\n",
    "model = Network()\n",
    "#model = models.resnet50(pretrained=True)\n",
    "#model.fc = nn.Linear(512 * 4, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Fehlerfunktion erstellen\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimierer (stochastic gradient descent) erstellen\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vorbereitung der Daten\n",
    "\n",
    "Die Trainings- und Validierungsdaten werden durch die Dataset Klasse geladen. Der Dataloader zieht Bilder aus dem Dataset und fügt sie zu Batches zusammen. Die Transformationen ```transforms.Resize```, ```transforms.ToTensor``` und ```transforms.Normalize``` werden mittels ```transforms.Compose``` zu einer Transformation zusammen gefügt. Die Transformation wird auf jedes zu ladende Bild angewendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Die Transformation formt das Eingabebild in einen Tensor um und normalisiert diesen.\n",
    "norm_mean = (0.485, 0.456, 0.406) # ImageNet mean color\n",
    "norm_std = (0.229, 0.224, 0.225) # ImageNet std \n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ])\n",
    "\n",
    "#Trainigsdatensatz\n",
    "trainset = ImageFolder(DATA_TRAIN, transform=transformations)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#Testdatensatz\n",
    "testset = ImageFolder(DATA_TEST, transform=transformations)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training und Validierung\n",
    "\n",
    "Die nächste Codezelle implementiert die Trainingsschleife, in der die Parameter des Netzwerks iterativ verbessert werden. Lassen Sie sich Zeit, den Ablauf genau zu verstehen. Der Code tut folgendes:\n",
    "\n",
    "1. Mithilfe der Funktionen ```utils.init_log``` eine Logdatei für die Trainingsergebnisse erzeugen - einmal für die Trainingsdaten und noch einmal für die Validierungsdaten\n",
    "2. In einer for-Schleife über die Epochen iterieren. Nutzen Sie die Funktion tqdm, um einen Ladebalken darzustellen.\n",
    "3. In einer Schleife über die Minibatches der Trainingsdaten iterieren, mit den Minibatches einen Forward Pass durchführen, den Fehler berechnen und die Parameter des Netzwerkes bei einem Optimierungsschritt anpassen\n",
    "4. Den aktuellen Fehler und die Genauigkeit auf den Trainingsdaten in die Logdatei schreiben mit ```utils.write_log```.\n",
    "5. In einer Schleife über die Minibatches der Validierungsdaten iterieren, mit den Minibatches einen Forward Pass durchführen und den Fehler berechnen.\n",
    "6. Den aktuellen Fehler und die Genauigkeit auf den Validierungsdaten in die Logdatei schreiben.\n",
    "7. Wenn MAX_EPOCH erreicht ist und das Training beendet ist, das Netzwerk auf der Platte abspeichern. Wir werden Ihr trainiertes Netzwerk morgen noch einmal benötigen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Die beiden Logdateien werden mit utils.init_log für das Training und das Testen erstellt\n",
    "utils.init_log(TRAIN_LOG_PATH)\n",
    "utils.init_log(TEST_LOG_PATH)\n",
    "\n",
    "for epoch in tqdm(range(1, MAX_EPOCH + 1)):\n",
    "    \n",
    "    ### Training ###\n",
    "    \n",
    "    # Die Listen 'losses' und 'correct' dienen dem Speichern der Zwischenergebnisse.\n",
    "    losses = []\n",
    "    correct = []\n",
    "    n_images = 0\n",
    "    \n",
    "    # WICHTIG! Das Netzwerk in den Trainingsmodus umschalten!\n",
    "    model.train()\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        # Nebenschleife über die Training Minibatches\n",
    "        \n",
    "        n_images += len(target)\n",
    "        \n",
    "        # Transferieren von data und target auf das Pytorch Device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Die gespeicherten Gradienten auf 0 setzen\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Fehler auf dem Batch berechnen\n",
    "        loss_batch = criterion(outputs, target)\n",
    "\n",
    "        # vorhergesage Labels bestimmmen und zählen, wie viele Labels korrekt vorausgesagt wurden.\n",
    "        pred = outputs.argmax(1)\n",
    "        correct_batch = (target == pred).sum()\n",
    "        \n",
    "        # Berechnung des Gradienten\n",
    "        loss_batch.backward()\n",
    "        \n",
    "        # Optimierungsschritt\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss_batch.item())\n",
    "        correct.append(correct_batch.item())\n",
    "        \n",
    "    losses = np.array(losses)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    # mittleren Fehler und die mittlere Genauigkeit berechnen\n",
    "    loss = losses.mean()\n",
    "    accuracy = correct.sum() / n_images\n",
    "    \n",
    "    # Speicherung der Zwischenergebnisse\n",
    "    utils.write_log(TRAIN_LOG_PATH, epoch, loss, accuracy)\n",
    "    \n",
    "    \n",
    "    ### Validierung ###\n",
    "    \n",
    "   losses = []\n",
    "    correct = []\n",
    "    n_images = 0\n",
    "    \n",
    "    # WICHTIG! Das Netzwerk in den Testmodus umschalten!\n",
    "    model.eval()\n",
    "    \n",
    "    # WICHTIG! Zur Validierung die Berechnung der Gradienten ausstellen!\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Nebenschleife über die Test Minibatches\n",
    "            \n",
    "            n_images += len(target)\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            \n",
    "            loss_batch = criterion(outputs, target)\n",
    "            \n",
    "           pred = outputs.argmax(1)\n",
    "            \n",
    "            correct_batch = (target == pred).sum()\n",
    "            \n",
    "            losses.append(loss_batch.item())\n",
    "            correct.append(correct_batch.item())\n",
    "        \n",
    "    losses = np.array(losses)\n",
    "    correct = np.array(correct)\n",
    "    loss = losses.mean()\n",
    "    accuracy = correct.sum() / n_images\n",
    "    utils.write_log(TEST_LOG_PATH, epoch, loss, accuracy)\n",
    "\n",
    "    # Plotten des mittleren Fehlers\n",
    "    utils.plot_loss(TRAIN_LOG_PATH, TEST_LOG_PATH)\n",
    "    # Plotten der mittleren Genauigkeit\n",
    "    utils.plot_accuracy(TRAIN_LOG_PATH, TEST_LOG_PATH)\n",
    "\n",
    "# Abspeichern des trainierten Netzwerks\n",
    "torch.save(model.state_dict(), MODEL_FILE_NAME)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jetzt sind Sie dran!\n",
    "\n",
    "Hier ein paar Ideen, wie Sie Ihren Algorithmus verbessern können:\n",
    "\n",
    "- Augmentieren Sie Ihre Trainingsdaten: Bildausschnitte, Skalierung, Kontraständerungen, Weißes Rauschen, Spiegelung, ... was hilft Ihnen bei diesem Problem weiter? Das Paket torchvision hat einige nützliche Funktionen zu bieten!\n",
    "- Ändern Sie Ihre Netzwerkarchitektur: Machen Sie das Netzwerk tiefer, flacher, weiter oder schmaler. Wie wirken sich Ihre Modifikationen auf Überanpassung und Genauigkeit aus?\n",
    "- Modifizieren Sie die Lernrate. Probieren Sie, die Lernrate nach einiger Zeit zu verringern. Gewinnen Sie dadurch an Genauigkeit?\n",
    "- Benutzen Sie einen anderen Optimierer wie Adam.\n",
    "- Nutzen Sie Regularisierung: Experimentieren Sie z.B. mit Momentum oder Weight Decay. \n",
    "- Nutzen Sie ein vortrainiertes Netzwerk\n",
    "- Falls Sie noch nicht genug haben: Trainieren Sie mehrere Netzwerke (nach einander), bündeln Sie sie zu einem Ensemble und nutzen Sie für die Validierung ihre gemittelte Ausgabe. Was müssen Sie bei der Mittelung der Ausgaben beachten?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
